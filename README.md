READ ME. DESCRIPTION:
Group Project: Charlotte Young, Hollis Hui, Lily Mccardle

Title: __ UNVEIL
Film Link: 
Youtube Link: 

Aims + Objectives:
• Using machine learning as a tool to explore group behaviour
• Explore the limits of machine learning in facial expression recognition
• Investigate the dynamics of group coordination and collaborative control
• Explore complex emergent behaviours through a set of basic rules

Proposal Project:

We propose an interactive installation that utilizes machine learning to explore the dynamics of group coordination, collaborative control, and non-verbal communication. This project aims to study the potential challenges of human interaction, as well as the limits of machine learning as a tool for facial expression recognition.
Across three interconnected display screens, a group of participants will be invited to work collaboratively to control their facial expressions. Each monitor uses computer vision to detect and analyze the facial keypoints in real-time, ensuring synchronized feedback and interaction across all screens. Once three expressions are successfully detected, this triggers a feedback response into the environment.

For this project, we are concerned with the complexity of generating feedback when given a set of basic rules, such as prohibiting the ability to speak during interaction. What types of emergent behavior and problems might arise from these restrictions? What constraints will this cause when acting as a group? Through the use of machine learning, we hope to see a sense of collaboration between technology and humans and thereby ask the relevant questions: What does it mean for a machine to ‘see’ and ‘recognise’ things? What happens when the machine learning model fails to recognise an expression, and would this then create a ‘blind spot’ that prevents a feedback response?






